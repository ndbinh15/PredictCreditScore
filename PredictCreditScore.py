# -*- coding: utf-8 -*-
"""N13_MIDTERM_PROBLEM1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11l9nBQEc7Qs7gEyDY8WtzaySvZXYAlOR

# **1.   KHAI BÁO THƯ VIỆN - ĐỌC DỮ LIỆU - SƠ LƯỢC DỮ LIỆU**
"""

import numpy as np
import pandas as pd
from scipy import stats
import seaborn as sns 
import matplotlib.pyplot as plt 

from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.neighbors import KDTree

from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

from sklearn import metrics
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score,  classification_report, confusion_matrix
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import r2_score
from sklearn.model_selection import cross_val_score

import time
import warnings
warnings.filterwarnings('ignore')

pd.set_option("display.max.columns", None)

df = pd.read_csv("/content/drive/MyDrive/ML 2022-23/Midterm/train.csv",sep = "," , encoding = "utf-8")
df_test = pd.read_csv("/content/drive/MyDrive/ML 2022-23/Midterm/test.csv",sep = "," , encoding = "utf-8")
# df.head()

df.columns

object_columns=list(df.select_dtypes(include='object').columns)
df[object_columns].head()

"""# **2.   CHUẨN HÓA DỮ LIỆU - FIX MISSING DATA - XÓA DỮ LIỆU NGOẠI LAI**


"""

df = df.applymap(lambda x: x if x is np.NaN or not isinstance(x, str) else str(x).strip('_ ,"')).replace(['', 'nan', '!@9#%8', '#F%$D@*&8'], np.NaN)

df['ID'] = df.ID.apply(lambda x: int(x, 16))
df['Customer_ID'] = df.Customer_ID.apply(lambda x: int(x[4:], 16))
df['Age'] = df.Age.astype(int)        
df['SSN'] = df.SSN.apply(lambda x: x if x is np.NaN else float(str(x).replace('-', ''))).astype(float)
df['Annual_Income'] = df.Annual_Income.astype(float)
df['Num_of_Loan'] = df.Num_of_Loan.astype(int) 
df['Num_of_Delayed_Payment'] = df.Num_of_Delayed_Payment.astype(float)
df['Changed_Credit_Limit'] = df.Changed_Credit_Limit.astype(float)
df['Outstanding_Debt'] = df.Outstanding_Debt.astype(float)
df['Amount_invested_monthly'] = df.Amount_invested_monthly.astype(float)
df['Monthly_Balance'] = df.Monthly_Balance.astype(float)

def Month_Converter(x):
  if pd.notnull(x):
    num1 = int(x.split(' ')[0])
    num2 = int(x.split(' ')[3])
    
    return num1*12+num2
  else:
    return x

df['Credit_History_Age'] = df.Credit_History_Age.apply(lambda x: Month_Converter(x)).astype(float)

df.head(3)

object_columns=list(df.select_dtypes(include='object').columns)
df[object_columns].head(3)

num_columns = list(df.select_dtypes(include=["int64","float64"]).columns)
df[num_columns].head()

#XÁC ĐỊNH CÁC CỘT CÓ DỮ LIỆU BỊ MISSING
def columns_with_missing_values(DataFrame):
  missing_columns=(DataFrame.isnull().sum())
  return missing_columns[missing_columns > 0]
columns_with_missing_values(df)

missing_columns=(df.isnull().sum())
miss_num_columns = list(df[(missing_columns[missing_columns > 0]).index].select_dtypes(include=["int64","float64"]).columns)
miss_object_columns=list(df[(missing_columns[missing_columns > 0]).index].select_dtypes(include='object').columns)

print(df.shape)
print(miss_num_columns)
print(miss_object_columns)

def Distribution2(columne,data,i):
  fig, ax = plt.subplots(1,3, figsize = (15,5))
  font_dict = {'fontsize': 14}
  title=['Before Distribution','After Distribution']
  ax = np.ravel(ax)
  if i==1:
    sns.set(style='whitegrid')
    sns.kdeplot(data=data,x=columne ,ax = ax[0],color='r').set_title(title[i])
    sns.boxplot(data=data,x=columne ,ax = ax[1],palette='magma').set_title(title[i])
    try:
      sns.histplot(data=data,x=columne,ax = ax[2], kde=True, color='r').set_title(title[i])
    except:
      sns.histplot(data=None,ax = ax[2], color='r').set_title(title[i])
  else:
    sns.set(style='whitegrid')
    sns.kdeplot(data=data,x=columne ,ax = ax[0],color='#2171b5').set_title(title[i])
    sns.boxplot(data=data,x=columne ,ax = ax[1],color='#2171b5').set_title(title[i])
    try:
      sns.histplot(data=data,x=columne ,ax = ax[2], kde=True,color='#2171b5').set_title(title[i])
    except:
      sns.histplot(data=None,ax = ax[2], color='#2171b5').set_title(title[i])
        
  ax = np.reshape(ax, (1, 3))
  plt.tight_layout()
  plt.show()

data=df.copy()
data.drop('SSN',axis=1,inplace=True)
data.shape

"""**CHUẨN HÓA CỘT "Monthly_Inhand_Salary"**"""

Distribution2(columne='Monthly_Inhand_Salary',data=data,i=0)

def get_Monthly_Inhand_Salary(row):
  if pd.isnull(row['Monthly_Inhand_Salary']):
    Monthly_Inhand_Salary=(data[data['Customer_ID']==row['Customer_ID']]['Monthly_Inhand_Salary'].dropna()).mode()
    try:
      return Monthly_Inhand_Salary[0]
    except:
      return np.NaN
  else:
    return row['Monthly_Inhand_Salary']
    
data['Monthly_Inhand_Salary']=data.apply(get_Monthly_Inhand_Salary,axis=1)

#Detect Outliers
print(data[data['Monthly_Inhand_Salary']>= 13500].shape)

data=data[data.Monthly_Inhand_Salary < 13500]
data.shape

Distribution2(columne='Monthly_Inhand_Salary',data=data,i=1)

"""**CHUẨN HÓA CỘT "Num_of_Delayed_Payment"**"""

Distribution2(columne='Num_of_Delayed_Payment',data=data,i=0)

def get_Num_of_Delayed_Payment(row):
  if pd.isnull(row['Num_of_Delayed_Payment']):
    Num_of_Delayed_Payment=(data[data['Customer_ID']==row['Customer_ID']]['Num_of_Delayed_Payment'].dropna()).mode()
    try:
      return Num_of_Delayed_Payment[0]
    except:
      return np.NaN
  else:
    return row['Num_of_Delayed_Payment']

data['Num_of_Delayed_Payment']=data.apply(get_Num_of_Delayed_Payment,axis=1)

#Detect outliers
print(data[data['Num_of_Delayed_Payment']>=150].shape)
print(data[data['Num_of_Delayed_Payment'] < 0].shape)

data=data[data['Num_of_Delayed_Payment']< 150]
data=data[data['Num_of_Delayed_Payment'] >= 0]
data.shape

Distribution2(columne='Num_of_Delayed_Payment',data=data,i=1)

"""**CHUẨN HÓA CỘT "Changed_Credit_Limit"**"""

Distribution2(columne='Changed_Credit_Limit',data=data,i=0)

def get_Changed_Credit_Limit(row):
  if pd.isnull(row['Changed_Credit_Limit']):
    Changed_Credit_Limit=(data[data['Customer_ID']==row['Customer_ID']]['Changed_Credit_Limit'].dropna()).mode()
    try:
      return Changed_Credit_Limit[0]
    except:
      return np.NaN
  else:
    return row['Changed_Credit_Limit']

data['Changed_Credit_Limit']=data.apply(get_Changed_Credit_Limit,axis=1)

#Detect Outliers
print(data[data['Changed_Credit_Limit']>=30].shape)

data=data[data['Changed_Credit_Limit'] < 30]
data.shape

Distribution2(columne='Changed_Credit_Limit',data=data,i=1)

"""**CHUẨN HÓA CỘT "Num_Credit_Inquiries"**"""

Distribution2(columne='Num_Credit_Inquiries',data=data,i=0)

def get_Num_Credit_Inquiries(row):
  if pd.isnull(row['Num_Credit_Inquiries']):
    Num_Credit_Inquiries=(data[data['Customer_ID']==row['Customer_ID']]['Num_Credit_Inquiries'].dropna()).mode()
    try:
      return Num_Credit_Inquiries[0]
    except:
      return np.NaN
  else:
    return row['Num_Credit_Inquiries']
data['Num_Credit_Inquiries']=data.apply(get_Num_Credit_Inquiries,axis=1)

#Detect Outliers
print(data[data['Num_Credit_Inquiries']>=50].shape)

data=data[data['Num_Credit_Inquiries']<50]
data.shape

Distribution2(columne='Num_Credit_Inquiries',data=data,i=1)

"""**CHUẨN HÓA CỘT "Credit_History_Age"**"""

Distribution2(columne='Credit_History_Age',data=data,i=0)

def get_Credit_History_Age(row):
  if pd.isnull(row['Credit_History_Age']):
    Credit_History_Age=(data[data['Customer_ID']==row['Customer_ID']]['Credit_History_Age'].dropna()).mode()
    try:
      return Credit_History_Age[0]
    except:
      return np.NaN
  else:
    return row['Credit_History_Age']

data['Credit_History_Age']=data.apply(get_Credit_History_Age,axis=1)

Distribution2(columne='Credit_History_Age',data=data,i=1)

"""**CHUẨN HÓA CỘT "Amount_invested_monthly"**"""

Distribution2(columne='Amount_invested_monthly',data=data,i=0)

def get_Amount_invested_monthly(row):
  if pd.isnull(row['Amount_invested_monthly']):
    Amount_invested_monthly=(data[data['Customer_ID']==row['Customer_ID']]['Amount_invested_monthly'].dropna()).mode()
    try:
      return Amount_invested_monthly[0]
    except:
      return np.NaN
  else:
    return row['Amount_invested_monthly']

data['Amount_invested_monthly']=data.apply(get_Amount_invested_monthly,axis=1)

#Detect Outliers
print(data[data['Amount_invested_monthly']>=1000].shape)

data=data[data['Amount_invested_monthly']<1000]
data.shape

Distribution2(columne='Amount_invested_monthly',data=data,i=1)

"""**CHUẨN HÓA CỘT "Monthly_Balance"**"""

Distribution2(columne='Monthly_Balance',data=data,i=0)

def get_Monthly_Balance(row):
    if pd.isnull(row['Monthly_Balance']):
        Monthly_Balance=(data[data['Customer_ID']==row['Customer_ID']]['Monthly_Balance'].dropna()).mode()
        try:
            return Monthly_Balance[0]
        except:
            return np.NaN
    else:
        return row['Monthly_Balance']

data['Monthly_Balance']=data.apply(get_Monthly_Balance,axis=1)

#Detect Outliers
print(data[data['Monthly_Balance'] <= 0].shape)

data = data[data['Monthly_Balance'] > 0]
data.shape

Distribution2(columne='Monthly_Balance',data=data,i=1)

#CONFIRM CÁC CỘT CÓ DỮ LIỆU BỊ MISSING ĐÃ ĐƯỢC FILL VÀ CHƯA ĐƯỢC FILL
missing_columns=data.isnull().sum()
miss_num_columns = list(data[(missing_columns[missing_columns > 0]).index].select_dtypes(include=["int64","float64"]).columns)
miss_object_columns=list(data[(missing_columns[missing_columns > 0]).index].select_dtypes(include='object').columns)

print(data.shape)
print(miss_num_columns)
print(miss_object_columns)

print(columns_with_missing_values(data))

"""**CHUẨN HÓA CỘT "Occupation"**"""

def get_Occupation(row):
  if pd.isnull(row['Occupation']):
    Occupation=(data[data['Customer_ID']==row['Customer_ID']]['Occupation'].dropna()).mode()
    try:
      return Occupation[0]
    except:
      return np.NaN
  else:
    return row['Occupation']

data['Occupation']=data.apply(get_Occupation,axis=1)

data['Occupation'] = data['Occupation'].fillna(data['Occupation'].mode()[0])
len(data[data['Occupation'].isnull()])

"""**CHUẨN HÓA CỘT "Type_of_Loan"**"""

data['Type_of_Loan'] = data['Type_of_Loan'].fillna('Not Specified')

#Split 'Type_of_Loan' to many columns, each of them have one feture of 'Type_of_Loan'
def get_Diff_Values_Colum(df_data):
  valu=['Auto Loan','Credit-Builder Loan','Debt Consolidation Loan','Home Equity Loan',
        'Mortgage Loan','Not Specified','Payday Loan','Personal Loan','Student Loan']
  for x in valu:
    df_data[x] = np.NAN
      
  index=0
  for i in df_data['Type_of_Loan']:
    diff_value=[]
    if ',' not in i:
      diff_value.append(i.strip())
    else:
      for data in map(lambda x:x.strip(), i.replace('and','').split(',')):
        if not data in diff_value:
          diff_value.append(data)
    
    for x in valu:
      if x in diff_value:
        df_data[x].iloc[index]=1
    index=index+1
      
  for x in valu:
    df_data[x] = df_data[x].fillna(0)
    df_data[x] = df_data[x].astype(int) 
  return df_data

data=get_Diff_Values_Colum(data)

data.drop('Type_of_Loan',axis=1,inplace=True)
data.head(2)

data.shape

"""**CHUẨN HÓA CỘT "Credit_Mix"**"""

def get_Credit_Mix(row):
  if pd.isnull(row['Credit_Mix']):
    Credit_Mix=(data[data['Customer_ID']==row['Customer_ID']]['Credit_Mix'].dropna()).mode()
    try:
      return Credit_Mix[0]
    except:
      return np.NaN
  else:
    return row['Credit_Mix']

len(data[data['Credit_Mix'].isnull()])

data['Credit_Mix']=data.apply(get_Credit_Mix,axis=1)
data['Credit_Mix'] = data['Credit_Mix'].fillna(data['Credit_Mix'].mode()[0])
len(data[data['Credit_Mix'].isnull()])

"""**CHUẨN HÓA CỘT "Payment_Behaviour"**"""

def get_Payment_Behaviour(row):
  if pd.isnull(row['Payment_Behaviour']):
    Payment_Behaviour=(data[data['Customer_ID']==row['Customer_ID']]['Payment_Behaviour'].dropna()).mode()
    try:
      return Payment_Behaviour[0]
    except:
      return np.NaN
  else:
    return row['Payment_Behaviour']

len(data[data['Payment_Behaviour'].isnull()])

data['Payment_Behaviour']=data.apply(get_Payment_Behaviour,axis=1)
data['Payment_Behaviour'] = data['Payment_Behaviour'].fillna(data['Payment_Behaviour'].mode()[0])
len(data[data['Payment_Behaviour'].isnull()])

# CHECK XEM CÁC CỘT NÀO CHƯA ĐƯỢC DETECT
num_columns = list(data.select_dtypes(include=["int64","float64",'int32']).columns)
num_columns=num_columns[2:-9]
process=['Monthly_Inhand_Salary','Num_of_Delayed_Payment','Changed_Credit_Limit','Num_Credit_Inquiries',
         'Credit_History_Age','Amount_invested_monthly','Monthly_Balance']

for i in num_columns:
  if i not in process:
    print(i)

"""**CHUẨN HÓA CỘT "Age"**"""

Distribution2(columne='Age',data=data,i=0)

print(data[data['Age'] > 60].shape)

def get_age(row):
  if (60 < row['Age']) or (0 > row['Age']) :
    Age=(data[data['Customer_ID']==row['Customer_ID']]['Age'].dropna()).mode()
    try:
      return Age[0]
    except:
      return np.NaN
  else:
    return row['Age']

data['Age']=data.apply(get_age,axis=1)

data[data['Age'] > 60].sort_values('Age')

data.drop(data[data['Age'] > 60].index,axis=0,inplace=True)
data[data['Age'] < 0].sort_values('Age')

data.drop(data[data['Age']  < 0].index,axis=0,inplace=True)
Distribution2(columne='Age',data=data,i=1)

"""**CHUẨN HÓA CỘT "Annual_Income"**"""

Distribution2(columne='Annual_Income',data=data,i=0)

def get_Annual_Income(row):
  if 150000 < row['Annual_Income'] :
    Annual_Income=(data[data['Customer_ID']==row['Customer_ID']]['Annual_Income'].dropna()).mode()
    try:
      return Annual_Income[0]
    except:
      return np.NaN
  else:
    return row['Annual_Income']
    
data['Annual_Income']=data.apply(get_Annual_Income,axis=1)

data[data['Annual_Income'] > 165000].sort_values('Annual_Income')

data.drop(data[data['Annual_Income']  > 165000].index,axis=0,inplace=True)
Distribution2(columne='Annual_Income',data=data,i=1)

"""**CHUẨN HÓA CỘT "Num_Bank_Accounts"**"""

Distribution2(columne='Num_Bank_Accounts',data=data,i=0)

def get_Num_Bank_Accounts(row):
    if 12 < row['Num_Bank_Accounts'] :
        Num_Bank_Accounts=(data[data['Customer_ID']==row['Customer_ID']]['Num_Bank_Accounts'].dropna()).mode()
        try:
            return Num_Bank_Accounts[0]
        except:
            return np.NaN
    else:
        return row['Num_Bank_Accounts']

data['Num_Bank_Accounts']=data.apply(get_Num_Bank_Accounts,axis=1)

data[data['Num_Bank_Accounts'] > 12]

data.drop(data[data['Num_Bank_Accounts']  > 12].index,axis=0,inplace=True)
data.drop(data[data['Num_Bank_Accounts']  < 0].index,axis=0,inplace=True)

Distribution2(columne='Num_Bank_Accounts',data=data,i=1)

"""**CHUẨN HÓA CỘT 'Num_Credit_Card"**"""

Distribution2(columne='Num_Credit_Card',data=data,i=0)

data[data['Num_Credit_Card'] > 14]

def get_Num_Credit_Card(row):
  if 14 < row['Num_Credit_Card'] :
    Num_Credit_Card=(data[data['Customer_ID']==row['Customer_ID']]['Num_Credit_Card'].dropna()).mode()
    try:
      return Num_Credit_Card[0]
    except:
      return np.NaN
  else:
    return row['Num_Credit_Card']

data['Num_Credit_Card']=data.apply(get_Num_Credit_Card,axis=1)

data.drop(data[data['Num_Credit_Card']  > 14].index,axis=0,inplace=True)
Distribution2(columne='Num_Credit_Card',data=data,i=1)

"""**CHUẨN HÓA CỘT "Interest_Rate"**"""

Distribution2(columne='Interest_Rate',data=data,i=0)

data[data['Interest_Rate'] > 35].sort_values('Interest_Rate')

def get_Interest_Rate(row):
  if 35 < row['Interest_Rate'] :
    Interest_Rate=(data[data['Customer_ID']==row['Customer_ID']]['Interest_Rate'].dropna()).mode()
    try:
      return Interest_Rate[0]
    except:
      return np.NaN
  else:
    return row['Interest_Rate']

data['Interest_Rate']=data.apply(get_Interest_Rate,axis=1)

Distribution2(columne='Interest_Rate',data=data,i=1)

"""**CHUẨN HÓA CỘT "Num_of_Loan"**"""

Distribution2(columne='Num_of_Loan',data=data,i=0)

def get_Num_of_Loan(row):
  if (8 < row['Num_of_Loan']) or (0 > row['Num_of_Loan']):
    Num_of_Loan=(data[data['Customer_ID']==row['Customer_ID']]['Num_of_Loan'].dropna()).mode()
    try:
      return Num_of_Loan[0]
    except:
      return np.NaN
  else:
    return row['Num_of_Loan']

data['Num_of_Loan']=data.apply(get_Num_of_Loan,axis=1)
data.drop(data[data['Num_of_Loan']  < 0].index,axis=0,inplace=True)

Distribution2(columne='Num_of_Loan',data=data,i=1)

"""**XEM CỘT "Delay_from_due_date"**"""

Distribution2(columne='Delay_from_due_date',data=data,i=0)

"""**XEM CỘT "Outstanding_Debt"**"""

Distribution2(columne='Outstanding_Debt',data=data,i=0)

"""**XEM CỘT "Credit_Utilization_Ratio"**"""

Distribution2(columne='Credit_Utilization_Ratio',data=data,i=0)

"""**CHUẨN HÓA CỘT "Total_EMI_per_month"**"""

Distribution2(columne='Total_EMI_per_month',data=data,i=0)

data=data[data['Total_EMI_per_month']<5000]
Distribution2(columne='Total_EMI_per_month',data=data,i=1)

data.shape

#CONFIRM CÁC CỘT CÓ DỮ LIỆU BỊ MISSING ĐÃ ĐƯỢC FILL
missing_columns=data.isnull().sum()
miss_num_columns = list(data[(missing_columns[missing_columns > 0]).index].select_dtypes(include=["int64","float64"]).columns)

print(data.shape)
print(miss_num_columns)

"""**Save process DATA to CSV**"""

data.to_csv("/content/drive/MyDrive/ML 2022-23/Midterm/data.csv", index=False)

"""# **3.   ĐỌC DATASET ĐÃ ĐƯỢC CHUẨN HÓA DỮ LIỆU**


"""

process_df= pd.read_csv("/content/drive/MyDrive/ML 2022-23/Midterm/data.csv",sep = "," , encoding = "utf-8")
process_df.head(3)

"""**Drop unimportant columns**"""

def drop_columns(DataFrame):
  list_unneed=['ID','Customer_ID','Name']
  DataFrame.drop(list_unneed, axis=1, inplace=True)

drop_columns(process_df)

"""**Encoding categorical features**"""

process_df['Month'] = process_df['Month'].map({'January':1, 'February':2, 'March':3, 'April':4, 'May':5, 'June':6, 'July':7, 'August':8, 'September':9, 'October':10, 'November':11, 'December':12})

Occupation_le = LabelEncoder()

process_df['Occupation'] = Occupation_le.fit_transform(process_df['Occupation'])
Occupation_le.classes_

Credit_Mix_le = LabelEncoder()

process_df['Credit_Mix'] = Credit_Mix_le.fit_transform(process_df['Credit_Mix'])
Credit_Mix_le.classes_

Payment_Behaviour_le = LabelEncoder()

process_df['Payment_Behaviour'] = Payment_Behaviour_le.fit_transform(process_df['Payment_Behaviour'])
Payment_Behaviour_le.classes_

Payment_of_Min_Amount_le = LabelEncoder()
process_df['Payment_of_Min_Amount'] = Payment_of_Min_Amount_le.fit_transform(process_df['Payment_of_Min_Amount'])
Payment_of_Min_Amount_le.classes_

process_df.head(10)

"""**Scaling and Split the data**"""

x = process_df.drop('Credit_Score',axis=1)
y = process_df['Credit_Score']

scaler = MinMaxScaler()
scaler.fit_transform(x)
X_scaled = scaler.transform(x)
X_train, X_test, y_train, y_test = train_test_split(X_scaled,y,random_state=44,test_size=0.3)

"""# **4.   MODEL**


"""

def score_show(model, y_test, y_pred, start_time1, end_time1, start_time2, end_time2):
  show_report(y_test, y_pred)
  # show_kFold(model)
  ls = show_time(start_time1, end_time1, start_time2, end_time2)
  print("Training time: %.2f (s)" % ls[0])
  print("Testing time: %.2f (s)" % ls[1])
  show_sample_results(y_test, y_pred)
  display_confusion_matrix(y_test, y_pred)

def show_report(y_test, y_pred):
  print(classification_report(y_test, y_pred, target_names=['Poor', 'Standard','Good']))

def save_report(y_test, y_pred, start_time1, end_time1, start_time2, end_time2):
  report = classification_report(y_test, y_pred, target_names=['Poor', 'Standard','Good'], output_dict=True)
  time = show_time(start_time1, end_time1, start_time2, end_time2)
  return report, time

def show_time(start_time1, end_time1, start_time2, end_time2):
  train_time = (end_time1 - start_time1)
  test_time = (end_time2 - start_time2)
  ls = [train_time, test_time]
  return ls

def show_kFold(model):
  if model != None:
    scores = cross_val_score(model, X_train, y_train, cv = 5, scoring='accuracy')
    print("k-Fold Cross Validation:")
    print('Cross-validation scores:{}'.format(scores))
    print('Average cross-validation score: {:.4f}'.format(scores.mean()))

def show_sample_results(y_test, y_pred):
  df2 = pd.DataFrame({"Y_pred" : y_pred,"Y_test": y_test})
  print("\n",df2.head(15))

def display_confusion_matrix(y_test, y_pred):
  confusion_matrix = metrics.confusion_matrix(y_test, y_pred)
  cmx_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = ['Poor', 'Standard','Good'])
  fig, ax = plt.subplots(figsize=(8,5))
  ax.grid(False)
  cmx_display.plot(ax=ax)

"""**1.   NaiveBayers**


"""

start_time1 = time.time()
nb=GaussianNB()
nb.fit(X_train, y_train)
end_time1 = time.time()
start_time2 = time.time()
y_pred = nb.predict(X_test)
end_time2 = time.time()

score_show(nb, y_test, y_pred, start_time1, end_time1, start_time2, end_time2)
nb_score, nb_time = save_report(y_test, y_pred, start_time1, end_time1, start_time2, end_time2)

"""**2.   KNeighborsClassifier**

"""

start_time1 = time.time()
knn = KNeighborsClassifier(n_neighbors=10)
knn.fit(X_train , y_train)
end_time1 = time.time()
start_time2 = time.time()
y_pred = knn.predict(X_test)
end_time2 = time.time()

score_show(knn, y_test, y_pred, start_time1, end_time1, start_time2, end_time2)
knn_score, knn_time  = save_report(y_test, y_pred, start_time1, end_time1, start_time2, end_time2)

"""**3.   DecisionTreeClassifier**

"""

start_time1 = time.time()
dt=DecisionTreeClassifier(max_depth=7)
dt.fit(X_train, y_train)
end_time1 = time.time()
start_time2 = time.time()
y_pred = dt.predict(X_test)
end_time2 = time.time()

score_show(dt, y_test, y_pred, start_time1, end_time1, start_time2, end_time2)
dt_score, dt_time = save_report(y_test, y_pred, start_time1, end_time1, start_time2, end_time2)

# from sklearn import tree

# fig = plt.figure(figsize=(15,12))
# tree.plot_tree(dt, filled=True)
# plt.show()

"""**4.   RandomForestClassifier**"""

start_time1 = time.time()
rf=RandomForestClassifier(n_estimators=200,criterion="entropy")
rf.fit(X_train, y_train)
end_time1 = time.time()
start_time2 = time.time()
y_pred = rf.predict(X_test)
end_time2 = time.time()

score_show(rf, y_test, y_pred, start_time1, end_time1, start_time2, end_time2)
rf_score, rf_time = save_report(y_test, y_pred, start_time1, end_time1, start_time2, end_time2)

# plt.figure(figsize=(15,10))
# importance = rf.feature_importances_
# idxs = np.argsort(importance)
# plt.title("Feature Importance")
# plt.barh(range(len(idxs)),importance[idxs],align="center")
# plt.yticks(range(len(idxs)),[col[i] for i in idxs])
# plt.xlabel("Random Forest Feature Importance")
#plt.tight_layout()
# plt.show()

"""**5.   SVM(Support Vector Machines)**"""

start_time1 = time.time()
svc=SVC(kernel="linear")
svc.fit(X_train, y_train)
end_time1 = time.time()
start_time2 = time.time()
y_pred = svc.predict(X_test)
end_time2 = time.time()

score_show(None, y_test, y_pred, start_time1, end_time1, start_time2, end_time2)
svc_score, svc_time = save_report(y_test, y_pred, start_time1, end_time1, start_time2, end_time2)

print(dt_time[0], nb_time[0])

dataa={"Precision Poor": [nb_score['Poor']['precision'], knn_score['Poor']['precision'],
                          dt_score['Poor']['precision'], rf_score['Poor']['precision'], 
                          svc_score['Poor']['precision']],
       "Precision Standard": [nb_score['Standard']['precision'], knn_score['Standard']['precision'],
                          dt_score['Standard']['precision'], rf_score['Standard']['precision'], 
                          svc_score['Standard']['precision']],
       "Precision Good": [nb_score['Good']['precision'], knn_score['Good']['precision'],
                          dt_score['Good']['precision'], rf_score['Good']['precision'], 
                          svc_score['Good']['precision']],
       "Recall Poor": [nb_score['Poor']['recall'], knn_score['Poor']['recall'],
                          dt_score['Poor']['recall'], rf_score['Poor']['recall'], 
                          svc_score['Poor']['recall']],
       "Recall Standard": [nb_score['Standard']['recall'], knn_score['Standard']['recall'],
                          dt_score['Standard']['recall'], rf_score['Standard']['recall'], 
                          svc_score['Standard']['recall']],
       "Recall Good": [nb_score['Good']['recall'], knn_score['Good']['recall'],
                          dt_score['Good']['recall'], rf_score['Good']['recall'], 
                          svc_score['Good']['recall']],
       "F1-score Poor": [nb_score['Poor']['f1-score'], knn_score['Poor']['f1-score'],
                          dt_score['Poor']['f1-score'], rf_score['Poor']['f1-score'], 
                          svc_score['Poor']['f1-score']],
       "F1-score Standard": [nb_score['Standard']['f1-score'], knn_score['Standard']['f1-score'],
                          dt_score['Standard']['f1-score'], rf_score['Standard']['f1-score'], 
                          svc_score['Standard']['f1-score']],
       "F1-score Good": [nb_score['Good']['f1-score'], knn_score['Good']['f1-score'],
                          dt_score['Good']['f1-score'], rf_score['Good']['f1-score'], 
                          svc_score['Good']['f1-score']],

       "Accuracy": [nb_score['accuracy'], knn_score['accuracy'],dt_score['accuracy'], 
                    rf_score['accuracy'], svc_score['accuracy']],
       "Weighted avg": [nb_score['weighted avg']['f1-score'], knn_score['weighted avg']['f1-score'],
                        dt_score['weighted avg']['f1-score'], rf_score['weighted avg']['f1-score'], 
                        svc_score['weighted avg']['f1-score']],
       "Training time": [nb_time[0], knn_time[0], dt_time[0], rf_time[0], svc_time[0]],
       "Testing time": [nb_time[1], knn_time[1], dt_time[1], rf_time[1], svc_time[1] ]
       }
df = pd.DataFrame(dataa, index = ["NaiveBayers", "KNeighbors", "DecisionTree",
                                  "RandomForest", "SVM"])
print(df)